#!/usr/bin/env python3
"""
Tech Challenge - Fase 4: An√°lise de V√≠deo
Script principal para processamento via linha de comando.

Uso:
    python main.py [caminho_video] [--output OUTPUT] [--skip N] [--show]
"""

import sys
import argparse
import cv2
import time
from pathlib import Path
from collections import Counter

from src import (
    FaceDetector, EmotionAnalyzer, ActivityDetector, 
    AnomalyDetector, draw_detections
)
from src.config import FRAME_SKIP, VIDEO_PATH, OUTPUT_DIR


def print_banner():
    """Exibe banner do programa."""
    print("=" * 70)
    print(" " * 15 + "TECH CHALLENGE - FASE 4")
    print(" " * 10 + "An√°lise de V√≠deo com IA")
    print("=" * 70)
    print()


def print_stats(stats, elapsed, total_frames, fps_processing):
    """Imprime estat√≠sticas da an√°lise no console."""
    print("\n" + "=" * 70)
    print(" " * 25 + "RESULTADOS DA AN√ÅLISE")
    print("=" * 70)
    
    print(f"\n‚è±Ô∏è  DESEMPENHO:")
    print(f"   ‚Ä¢ Tempo total: {elapsed:.1f}s")
    print(f"   ‚Ä¢ FPS processamento: {fps_processing:.1f} fps")
    print(f"   ‚Ä¢ Frames processados: {total_frames}")
    
    print(f"\nüë§ DETEC√á√ÉO DE FACES:")
    print(f"   ‚Ä¢ Total de faces detectadas: {stats['faces']}")
    
    if stats['emotions']:
        print(f"\nüòä AN√ÅLISE DE EMO√á√ïES (Top 5):")
        for i, (emotion, count) in enumerate(stats['emotions'].most_common(5), 1):
            bar = "‚ñà" * int(count / max(stats['emotions'].values()) * 30)
            print(f"   {i}. {emotion:15s} ‚îÇ {bar} {count}")
    
    if stats['activities']:
        print(f"\nüèÉ ATIVIDADES DETECTADAS (Top 5):")
        for i, (activity, count) in enumerate(stats['activities'].most_common(5), 1):
            bar = "‚ñà" * int(count / max(stats['activities'].values()) * 30)
            print(f"   {i}. {activity:20s} ‚îÇ {bar} {count}")
    
    total_anomalies = sum(stats['anomalies'].values())
    if total_anomalies > 0:
        print(f"\n‚ö†Ô∏è  ANOMALIAS DETECTADAS:")
        print(f"   ‚Ä¢ Total: {total_anomalies}")
        for anom_type, count in stats['anomalies'].most_common():
            print(f"     - {anom_type}: {count}")
    else:
        print(f"\n‚úÖ Nenhuma anomalia detectada")
    
    print("\n" + "=" * 70)


def process_video(video_path, output_path, frame_skip=2, min_face_size=40):
    """
    Processa o v√≠deo completo.
    
    Args:
        video_path: Caminho do v√≠deo de entrada
        output_path: Caminho do v√≠deo de sa√≠da
        frame_skip: Intervalo de frames para detec√ß√£o
        min_face_size: Tamanho m√≠nimo de face em pixels
    
    Returns:
        dict: Estat√≠sticas da an√°lise
    """
    # Inicializa detectores
    print("üîß Inicializando modelos de IA...")
    face_detector = FaceDetector(method="haar")
    emotion_analyzer = EmotionAnalyzer(method="fer")
    activity_detector = ActivityDetector(model_size="s")
    anomaly_detector = AnomalyDetector()
    print("‚úÖ Modelos carregados!\n")
    
    # Abre v√≠deo
    cap = cv2.VideoCapture(str(video_path))
    if not cap.isOpened():
        raise ValueError(f"N√£o foi poss√≠vel abrir o v√≠deo: {video_path}")
    
    # Propriedades do v√≠deo
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    print(f"üìπ V√≠deo de entrada:")
    print(f"   ‚Ä¢ Arquivo: {Path(video_path).name}")
    print(f"   ‚Ä¢ Resolu√ß√£o: {width}x{height}")
    print(f"   ‚Ä¢ FPS: {fps:.1f}")
    print(f"   ‚Ä¢ Frames totais: {total_frames}")
    print(f"   ‚Ä¢ Dura√ß√£o: {total_frames/fps:.1f}s\n")
    
    # Configura gravador
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(str(output_path), fourcc, fps, (width, height))
    
    # Estat√≠sticas
    stats = {
        'faces': 0,
        'emotions': Counter(),
        'activities': Counter(),
        'anomalies': Counter()
    }
    
    # Cache de detec√ß√µes
    cache = {
        'faces': [],
        'emotions': [],
        'activities': [],
        'anomalies': []
    }
    
    # Processamento
    frame_idx = 0
    start_time = time.time()
    last_progress = 0
    
    print("üé¨ Processando v√≠deo...")
    print("‚îå" + "‚îÄ" * 68 + "‚îê")
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        # Detec√ß√£o a cada N frames
        if frame_idx % frame_skip == 0:
            # Faces
            cache['faces'] = face_detector.detect(frame)
            stats['faces'] += len(cache['faces'])
            
            # Emo√ß√µes
            cache['emotions'] = []
            for face in cache['faces']:
                if face.bbox[2] >= min_face_size:
                    emotion = emotion_analyzer.analyze(frame, face.bbox, face.face_id)
                    cache['emotions'].append(emotion)
                    if emotion:
                        stats['emotions'][emotion.emotion_pt] += 1
                else:
                    cache['emotions'].append(None)
            
            # Atividades
            cache['activities'] = activity_detector.detect(frame)
            for activity in cache['activities']:
                stats['activities'][activity.activity_pt] += 1
            
            # Anomalias
            cache['anomalies'] = anomaly_detector.update(
                frame_idx,
                cache['faces'],
                [e for e in cache['emotions'] if e],
                cache['activities']
            )
            for anomaly in cache['anomalies']:
                stats['anomalies'][anomaly.anomaly_type] += 1
        
        # Desenha anota√ß√µes
        annotated = draw_detections(
            frame,
            cache['faces'],
            cache['emotions'],
            cache['activities'],
            cache['anomalies'],
            min_face_size
        )
        out.write(annotated)
        
        # Barra de progresso
        progress = int((frame_idx / total_frames) * 100)
        if progress > last_progress:
            bar_length = 50
            filled = int(bar_length * progress / 100)
            bar = "‚ñà" * filled + "‚ñë" * (bar_length - filled)
            elapsed = time.time() - start_time
            fps_proc = frame_idx / elapsed if elapsed > 0 else 0
            eta = (total_frames - frame_idx) / fps_proc if fps_proc > 0 else 0
            
            print(f"\r‚îÇ {bar} ‚îÇ {progress:3d}% ‚îÇ {fps_proc:5.1f} fps ‚îÇ ETA: {eta:5.0f}s ", end="", flush=True)
            last_progress = progress
        
        frame_idx += 1
    
    print(f"\r‚îÇ {'‚ñà' * 50} ‚îÇ 100% ‚îÇ                    ")
    print("‚îî" + "‚îÄ" * 68 + "‚îò\n")
    
    cap.release()
    out.release()
    
    elapsed = time.time() - start_time
    fps_processing = frame_idx / elapsed
    
    return stats, elapsed, total_frames, fps_processing, output_path


def play_video(video_path):
    """
    Reproduz o v√≠deo usando OpenCV (player embutido).
    
    Args:
        video_path: Caminho do v√≠deo a ser reproduzido
    """
    video_path = Path(video_path)
    if not video_path.exists():
        print(f"‚ùå V√≠deo n√£o encontrado: {video_path}")
        return
    
    print(f"\n‚ñ∂Ô∏è  Reproduzindo: {video_path.name}")
    print("   Controles: [Q] Sair | [ESPA√áO] Pausar | [‚Üê/‚Üí] -10s/+10s")
    
    cap = cv2.VideoCapture(str(video_path))
    if not cap.isOpened():
        print(f"‚ùå N√£o foi poss√≠vel abrir o v√≠deo")
        return
    
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    delay = int(1000 / fps) if fps > 0 else 33  # ms entre frames
    
    window_name = "Tech Challenge - Video Analisado"
    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
    cv2.resizeWindow(window_name, 1280, 720)
    
    paused = False
    
    while True:
        if not paused:
            ret, frame = cap.read()
            if not ret:
                # Fim do v√≠deo - volta ao in√≠cio
                cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                continue
            
            # Mostra informa√ß√µes no frame
            current_frame = int(cap.get(cv2.CAP_PROP_POS_FRAMES))
            current_time = current_frame / fps
            total_time = total_frames / fps
            info = f"[{current_time:.1f}s / {total_time:.1f}s]"
            
            cv2.putText(frame, info, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 
                       0.7, (255, 255, 255), 2)
            
            cv2.imshow(window_name, frame)
        
        key = cv2.waitKey(delay if not paused else 100) & 0xFF
        
        if key == ord('q') or key == 27:  # Q ou ESC
            break
        elif key == ord(' '):  # Espa√ßo - pausar
            paused = not paused
            status = "PAUSADO" if paused else "REPRODUZINDO"
            print(f"\r   Status: {status}          ", end="", flush=True)
        elif key == 81 or key == ord('a'):  # Seta esquerda ou A - voltar 10s
            current = cap.get(cv2.CAP_PROP_POS_FRAMES)
            cap.set(cv2.CAP_PROP_POS_FRAMES, max(0, current - fps * 10))
        elif key == 83 or key == ord('d'):  # Seta direita ou D - avan√ßar 10s
            current = cap.get(cv2.CAP_PROP_POS_FRAMES)
            cap.set(cv2.CAP_PROP_POS_FRAMES, min(total_frames, current + fps * 10))
        
        # Verifica se a janela foi fechada
        if cv2.getWindowProperty(window_name, cv2.WND_PROP_VISIBLE) < 1:
            break
    
    cap.release()
    cv2.destroyAllWindows()
    print("\n‚úÖ Reprodu√ß√£o encerrada")


def main():
    """Fun√ß√£o principal."""
    parser = argparse.ArgumentParser(
        description="Tech Challenge Fase 4 - An√°lise de V√≠deo com IA",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemplos:
  python main.py                                    # Usa v√≠deo padr√£o
  python main.py input/meu_video.mp4                # V√≠deo espec√≠fico
  python main.py input/video.mp4 --skip 3           # Processa a cada 3 frames
  python main.py input/video.mp4 --show             # Reproduz ap√≥s processar
        """
    )
    
    parser.add_argument(
        'video',
        nargs='?',
        default=VIDEO_PATH,
        help='Caminho do v√≠deo de entrada (padr√£o: definido em config)'
    )
    parser.add_argument(
        '--output', '-o',
        help='Caminho do v√≠deo de sa√≠da (padr√£o: output/video_analisado.mp4)'
    )
    parser.add_argument(
        '--skip', '-s',
        type=int,
        default=FRAME_SKIP,
        help=f'Intervalo de frames para detec√ß√£o (padr√£o: {FRAME_SKIP})'
    )
    parser.add_argument(
        '--show',
        action='store_true',
        help='Reproduz o v√≠deo ap√≥s processamento'
    )
    parser.add_argument(
        '--min-face-size',
        type=int,
        default=40,
        help='Tamanho m√≠nimo de face em pixels (padr√£o: 40)'
    )
    
    args = parser.parse_args()
    
    # Valida entrada
    video_path = Path(args.video)
    if not video_path.exists():
        print(f"‚ùå Erro: V√≠deo n√£o encontrado: {video_path}")
        sys.exit(1)
    
    # Define sa√≠da
    if args.output:
        output_path = Path(args.output)
    else:
        output_path = OUTPUT_DIR / "video_analisado.mp4"
    
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    # Banner
    print_banner()
    
    try:
        # Processa v√≠deo
        stats, elapsed, total_frames, fps_proc, output_file = process_video(
            video_path,
            output_path,
            frame_skip=args.skip,
            min_face_size=args.min_face_size
        )
        
        # Mostra resultados
        print_stats(stats, elapsed, total_frames, fps_proc)
        
        # Info do arquivo de sa√≠da
        output_size = output_path.stat().st_size / (1024 * 1024)
        print(f"\nüíæ V√≠deo processado salvo:")
        print(f"   ‚Ä¢ Arquivo: {output_path}")
        print(f"   ‚Ä¢ Tamanho: {output_size:.1f} MB\n")
        
        # Reproduz se solicitado
        if args.show:
            play_video(output_path)
        else:
            print(f"üí° Para reproduzir o v√≠deo, execute:")
            print(f"   python main.py --show\n")
        
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Processamento cancelado pelo usu√°rio")
        sys.exit(130)
    except Exception as e:
        print(f"\n‚ùå Erro durante processamento: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
