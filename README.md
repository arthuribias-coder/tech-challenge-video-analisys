# Tech Challenge - Fase 4: AnÃ¡lise de VÃ­deo com IA

Este projeto consiste em uma aplicaÃ§Ã£o desktop avanÃ§ada para anÃ¡lise inteligente de vÃ­deos, desenvolvida como parte do Tech Challenge (Fase 4). A soluÃ§Ã£o utiliza tÃ©cnicas modernas de VisÃ£o Computacional e InteligÃªncia Artificial para extrair insights comportamentais, contextuais e emocionais de arquivos de vÃ­deo.

## ğŸ¯ Objetivo

O objetivo principal Ã© processar vÃ­deos de vigilÃ¢ncia ou monitoramento para identificar e rastrear pessoas, analisar suas atividades e emoÃ§Ãµes, entender o contexto do ambiente (cena) e detectar anomalias (comportamentos suspeitos ou objetos fora de contexto).

## ğŸš€ Funcionalidades Principais

* **DetecÃ§Ã£o e Rastreamento de Atividades**: Utiliza **YOLO11-pose** para identificar esqueletos e classificar aÃ§Ãµes (caminhando, correndo, sentado, acenando, etc.).
* **AnÃ¡lise de EmoÃ§Ãµes**: IntegraÃ§Ã£o com **DeepFace** para anÃ¡lise facial profunda, identificando emoÃ§Ãµes como alegria, tristeza, raiva, surpresa, etc.
* **DetecÃ§Ã£o de Pessoas Deitadas (Oriented Object Detection)**: Uso inovador do **YOLO11-obb** (Oriented Bounding Box) para distinguir com precisÃ£o entre pessoas em pÃ© e deitadas, crucial para detecÃ§Ã£o de quedas ou acidentes.
* **ClassificaÃ§Ã£o de Cena (Context Awareness)**: O sistema utiliza **YOLO11-cls** para identificar o ambiente (ex: escritÃ³rio, sala de estar, parque), permitindo validaÃ§Ãµes contextuais.
* **DetecÃ§Ã£o de Objetos Contextual**: Identifica objetos na cena (**YOLO11**) e valida se sÃ£o esperados ou anÃ´malos para aquele ambiente (ex: uma cama em um escritÃ³rio Ã© uma anomalia).
* **DetecÃ§Ã£o de Anomalias**: Motor de regras que combina dados comportamentais e visuais para alertar sobre:
  * Movimentos bruscos.
  * Picos de emoÃ§Ã£o negativa.
  * Inatividade prolongada.
  * InconsistÃªncias de cena (objetos proibidos).
* **Interface GrÃ¡fica Profissional**: Desenvolvida em **PyQt6**, com player de vÃ­deo, grÃ¡ficos em tempo real (PyQtCharts) e painÃ©is de estatÃ­sticas.
* **RelatÃ³rios AutomÃ¡ticos**: GeraÃ§Ã£o de relatÃ³rios em TXT com resumo das ocorrÃªncias.

## ğŸ—ï¸ Arquitetura e Fluxo de Processamento

A aplicaÃ§Ã£o segue uma arquitetura modular, onde uma Thread de Processamento (`ProcessorThreadQt`) orquestra a execuÃ§Ã£o sequencial dos modelos de IA frame a frame, sem congelar a interface do usuÃ¡rio.

### Pipeline de Processamento

O fluxo de anÃ¡lise Ã© executado sequencialmente para cada frame processado:

```mermaid
flowchart TD
    Input[ğŸ“¹ VÃ­deo] --> Capture[ğŸ¬ Captura]
    Capture --> Scene[ğŸï¸ Cena]
    Scene --> Pose[ğŸ§ Poses]
    Pose --> OBB[â†ªï¸ OrientaÃ§Ã£o]
    OBB --> Face[ğŸ‘¤ Faces]
    Face --> Emotion[ğŸ˜Š EmoÃ§Ãµes]
    Face --> Object[ğŸ“¦ Objetos]
    Object --> Anomaly[âš ï¸ Anomalias]
    Anomaly --> Gui[ğŸ¨ Interface]
```

| Ordem | MÃ³dulo | FunÃ§Ã£o Principal | Tecnologia |
| :---: | :--- | :--- | :--- |
| **1** | **SceneClassifier** | Identifica o contexto do ambiente (ex: "EscritÃ³rio", "Parque") | YOLO11-cls |
| **2** | **OrientedDetector** | Detecta a orientaÃ§Ã£o de pessoas (em pÃ© vs. deitado) | YOLO11-obb |
| **3** | **ActivityDetector** | Extrai poses esquelÃ©ticas e classifica aÃ§Ãµes | YOLO11-pose |
| **4** | **FaceDetector** | Recorta rostos baseando-se na geometria do corpo | HeurÃ­stica |
| **5** | **EmotionAnalyzer** | Analisa expressÃµes faciais nos recortes | DeepFace |
| **6** | **ObjectDetector** | Detecta objetos e valida coerÃªncia com a cena | YOLO11-detect |
| **7** | **AnomalyDetector** | Aplica regras para identificar comportamentos suspeitos | LÃ³gica |
| **8** | **Visualizer** | Renderiza anotaÃ§Ãµes e atualiza os grÃ¡ficos | OpenCV/Qt |

### Estrutura do Projeto

```text
TC-4/
â”œâ”€â”€ gui_app.py              # Ponto de entrada da aplicaÃ§Ã£o
â”œâ”€â”€ requirements.txt        # Lista de dependÃªncias Python
â”œâ”€â”€ input/                  # DiretÃ³rio para vÃ­deos de entrada
â”œâ”€â”€ output/                 # DiretÃ³rio para vÃ­deos processados
â”œâ”€â”€ reports/                # RelatÃ³rios gerados
â”œâ”€â”€ models/                 # Pesos dos modelos YOLO e DeepFace
â””â”€â”€ src/
    â”œâ”€â”€ config.py           # ConfiguraÃ§Ãµes globais e regras de contexto
    â”œâ”€â”€ gui/                # Interface GrÃ¡fica (PyQt6)
    â”‚   â”œâ”€â”€ main_window_qt.py
    â”‚   â””â”€â”€ threads/processor_thread_qt.py # Orquestrador do pipeline
    â”œâ”€â”€ activity_detector.py # Wrapper YOLO11-pose
    â”œâ”€â”€ emotion_analyzer.py  # Wrapper DeepFace
    â”œâ”€â”€ face_detector.py     # LÃ³gica de extraÃ§Ã£o facial
    â”œâ”€â”€ scene_classifier.py  # Wrapper YOLO11-cls
    â”œâ”€â”€ oriented_detector.py # Wrapper YOLO11-obb
    â”œâ”€â”€ object_detector.py   # Wrapper YOLO11-detect
    â”œâ”€â”€ anomaly_detector.py  # Motor de regras de anomalia
    â””â”€â”€ visualizer.py        # RenderizaÃ§Ã£o visual (OpenCV/PIL)
```

## ğŸ› ï¸ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### PrÃ©-requisitos

* **Python 3.10** ou superior (3.12 recomendado).
* **GPU NVIDIA** (Opcional, mas altamente recomendado para performance em tempo real). Drivers CUDA instalados.

### Passo a Passo

1. **Clone o repositÃ³rio e navegue atÃ© a pasta:**

    ```bash
    git clone <url-do-repositorio>
    cd TC-4
    ```

2. **Crie e ative um ambiente virtual:**

    ```bash
    python3 -m venv .venv
    source .venv/bin/activate  # Linux/Mac
    # .venv\Scripts\activate   # Windows
    ```

3. **Instale as dependÃªncias:**

    ```bash
    pip install -r requirements.txt
    ```

    *Nota: A primeira execuÃ§Ã£o baixarÃ¡ automaticamente os modelos YOLO (~100MB cada) e DeepFace.*

4. **Execute a aplicaÃ§Ã£o:**

    ```bash
    python gui_app.py
    ```

## ğŸ“– Como Usar

1. A interface abrirÃ¡ automaticamente.
2. Clique no Ã­cone de **"Abrir Arquivo"** (canto superior esquerdo) para selecionar um vÃ­deo da pasta `input/`.
3. Ajuste as configuraÃ§Ãµes se necessÃ¡rio (botÃ£o "ConfiguraÃ§Ãµes"):
    * **Frame Skip**: Aumente para maior velocidade (ex: 2 ou 3).
    * **Device**: CPU ou CUDA (GPU).
4. Clique no botÃ£o **Play** (â–¶) para iniciar a anÃ¡lise.
5. Acompanhe os resultados em tempo real:
    * **VÃ­deo**: VisualizaÃ§Ã£o com anotaÃ§Ãµes de bounding boxes e labels.
    * **EstatÃ­sticas**: Contadores de faces, anomalias e atividades.
    * **GrÃ¡ficos**: DistribuiÃ§Ã£o de emoÃ§Ãµes e atividades (abas na parte inferior).
6. Ao final, o vÃ­deo processado serÃ¡ salvo na pasta `output/` e um relatÃ³rio de texto em `reports/`.

## âš™ï¸ ConfiguraÃ§Ã£o TÃ©cnica (`src/config.py`)

O arquivo `src/config.py` centraliza constantes importantes, como:

* `SCENE_CONTEXT_RULES`: DicionÃ¡rio que define quais objetos sÃ£o esperados ou anÃ´malos em cada tipo de cena (escritÃ³rio, casa, rua).
* `ANOMALY_THRESHOLDS`: Limiares de sensibilidade para detecÃ§Ã£o de anomalias.
* `EMOTION_THRESHOLDS`: Sensibilidade para cada tipo de emoÃ§Ã£o.

---
**Tech Challenge Fase 4 - PÃ³s Tech Data Analytics**
