# Tech Challenge - Fase 4: AnÃ¡lise de VÃ­deo com IA

## DescriÃ§Ã£o

AplicaÃ§Ã£o de anÃ¡lise de vÃ­deo que utiliza tÃ©cnicas de **reconhecimento facial**, **anÃ¡lise de expressÃµes emocionais**, **detecÃ§Ã£o de atividades** e **identificaÃ§Ã£o de anomalias comportamentais**.

O sistema processa vÃ­deos em **tempo real**, exibindo bounding boxes, labels e informaÃ§Ãµes relevantes diretamente no vÃ­deo, similar a sistemas de detecÃ§Ã£o de objetos como YOLO.

## Funcionalidades

| Funcionalidade | DescriÃ§Ã£o |
|----------------|-----------|
| **Reconhecimento Facial** | Detecta e rastreia rostos no vÃ­deo, atribuindo IDs Ãºnicos |
| **AnÃ¡lise de EmoÃ§Ãµes** | Classifica expressÃµes faciais (feliz, triste, raiva, etc.) |
| **DetecÃ§Ã£o de Atividades** | Identifica aÃ§Ãµes (caminhando, sentado, gesticulando, etc.) |
| **DetecÃ§Ã£o de Anomalias** | Identifica comportamentos atÃ­picos (movimentos bruscos, mudanÃ§as emocionais sÃºbitas) |
| **GeraÃ§Ã£o de RelatÃ³rio** | Cria resumo automÃ¡tico com estatÃ­sticas e insights |

## Arquitetura

```
TC-4/
â”œâ”€â”€ main.py                 # Ponto de entrada principal
â”œâ”€â”€ requirements.txt        # DependÃªncias do projeto
â”œâ”€â”€ .env.example            # Exemplo de configuraÃ§Ã£o
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py         # Exporta mÃ³dulos principais
â”‚   â”œâ”€â”€ config.py           # ConfiguraÃ§Ãµes centralizadas
â”‚   â”œâ”€â”€ face_detector.py    # Detector de rostos
â”‚   â”œâ”€â”€ emotion_analyzer.py # Analisador de emoÃ§Ãµes
â”‚   â”œâ”€â”€ activity_detector.py# Detector de atividades (YOLO11-pose)
â”‚   â”œâ”€â”€ anomaly_detector.py # Detector de anomalias
â”‚   â”œâ”€â”€ visualizer.py       # Desenho de anotaÃ§Ãµes nos frames
â”‚   â””â”€â”€ report_generator.py # Gerador de relatÃ³rios
â”œâ”€â”€ input/                  # VÃ­deos de entrada
â”œâ”€â”€ output/                 # VÃ­deos processados
â”œâ”€â”€ reports/                # RelatÃ³rios gerados
â””â”€â”€ models/                 # Modelos YOLO baixados
```

## InstalaÃ§Ã£o

### 1. Clonar o repositÃ³rio

```bash
git clone <repo-url>
cd TC-4
```

### 2. Criar ambiente virtual (Python 3.12+)

```bash
python3.12 -m venv .venv
source .venv/bin/activate  # Linux/Mac
# ou
.venv\Scripts\activate     # Windows
```

### 3. Instalar dependÃªncias

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

### 4. Colocar o vÃ­deo na pasta `input/`

```bash
cp seu_video.mp4 input/
```

## Uso

### Processamento de VÃ­deo

```bash
# Ativar ambiente virtual (se ainda nÃ£o ativou)
source .venv/bin/activate

# Processar vÃ­deo padrÃ£o (definido em .env ou config.py)
python main.py

# Processar vÃ­deo especÃ­fico
python main.py input/seu_video.mp4

# Processar e reproduzir automaticamente (abre player OpenCV)
python main.py input/video.mp4 --show

# Ajustar intervalo de frames (mais rÃ¡pido, menos preciso)
python main.py input/video.mp4 --skip 3

# Definir arquivo de saÃ­da customizado
python main.py input/video.mp4 --output meu_resultado.mp4

# Ver todas as opÃ§Ãµes disponÃ­veis
python main.py --help
```

### Controles do Player (--show)

| Tecla | AÃ§Ã£o |
| --- | --- |
| **Q** ou **ESC** | Sair do player |
| **EspaÃ§o** | Pausar/Continuar |
| **â† / A** | Voltar 10 segundos |
| **â†’ / D** | AvanÃ§ar 10 segundos |

### SaÃ­da no Console

O sistema exibe em tempo real:

- ğŸ”§ Carregamento dos modelos de IA
- ğŸ“¹ InformaÃ§Ãµes do vÃ­deo de entrada
- ğŸ¬ Barra de progresso detalhada (%, FPS, ETA)
- ğŸ“Š EstatÃ­sticas completas da anÃ¡lise:
  - Total de faces detectadas
  - Top 5 emoÃ§Ãµes com grÃ¡fico ASCII
  - Top 5 atividades com grÃ¡fico ASCII
  - Anomalias detectadas
- ğŸ’¾ InformaÃ§Ãµes do arquivo gerado

## Tecnologias Utilizadas

| Categoria | Tecnologia |
| --- | --- |
| **VisÃ£o Computacional** | OpenCV, MediaPipe |
| **Reconhecimento Facial** | OpenCV Haar Cascades |
| **AnÃ¡lise de EmoÃ§Ãµes** | FER (Facial Expression Recognition) |
| **DetecÃ§Ã£o de Atividades** | YOLO11-pose (Ultralytics) |
| **Deep Learning** | PyTorch |

## VÃ­deo Processado

O vÃ­deo de saÃ­da contÃ©m:

- âœ… Bounding boxes verdes para rostos detectados
- ğŸ˜Š Labels de emoÃ§Ãµes com confianÃ§a (ciano)
- ğŸƒ DetecÃ§Ã£o de atividades das pessoas (laranja)
- âš ï¸ Alertas visuais para anomalias (vermelho)

## Estrutura dos MÃ³dulos

### FaceDetector (`src/face_detector.py`)

- MÃ©todo padrÃ£o: Haar Cascades
- Rastreamento de IDs entre frames
- Suporte para MediaPipe e DNN

### EmotionAnalyzer (`src/emotion_analyzer.py`)

- Baseado em FER (Facial Expression Recognition)
- SuavizaÃ§Ã£o temporal para reduzir ruÃ­do
- 7 emoÃ§Ãµes: feliz, triste, raiva, medo, surpresa, nojo, neutro

### ActivityDetector (`src/activity_detector.py`)

- Usa YOLO11-pose para detecÃ§Ã£o de pessoas
- AnÃ¡lise de keypoints (17 pontos COCO)
- Detecta 9 atividades: em pÃ©, sentado, caminhando, correndo, acenando, apontando, danÃ§ando, agachado, braÃ§os levantados

### AnomalyDetector (`src/anomaly_detector.py`)

- AnÃ¡lise estatÃ­stica de comportamento
- DetecÃ§Ã£o de: movimentos bruscos, mudanÃ§as emocionais sÃºbitas, atividades incomuns
- HistÃ³rico temporal para baseline adaptativo

## Notas Importantes

- âœ… Projeto convertido de notebooks para aplicaÃ§Ã£o CLI simples
- ğŸš€ Performance otimizada com `frame_skip` configurÃ¡vel
- ğŸ“¹ Suporta qualquer formato de vÃ­deo compatÃ­vel com OpenCV
- ğŸ¯ YOLO11-pose oferece melhor precisÃ£o que YOLOv8

## Autor

Desenvolvido para o Tech Challenge - Fase 4 do curso de PÃ³s-GraduaÃ§Ã£o.

## LicenÃ§a

Este projeto Ã© de uso educacional.
