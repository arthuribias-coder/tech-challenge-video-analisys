pre# Tech Challenge - Fase 4: An√°lise de V√≠deo com IA

Este projeto consiste em uma aplica√ß√£o desktop avan√ßada para an√°lise inteligente de v√≠deos, desenvolvida como parte do Tech Challenge (Fase 4). A solu√ß√£o utiliza t√©cnicas modernas de Vis√£o Computacional e Intelig√™ncia Artificial para extrair insights comportamentais, contextuais e emocionais de arquivos de v√≠deo.

## üéØ Objetivo

O objetivo principal √© processar v√≠deos de vigil√¢ncia ou monitoramento para identificar e rastrear pessoas, analisar suas atividades e emo√ß√µes, entender o contexto do ambiente (cena) e detectar anomalias (comportamentos suspeitos ou objetos fora de contexto).

## üöÄ Funcionalidades Principais

* **Detec√ß√£o e Rastreamento de Atividades**: Utiliza **YOLO11-pose** para identificar esqueletos e classificar a√ß√µes (caminhando, correndo, sentado, acenando, etc.).
* **An√°lise de Emo√ß√µes**: Integra√ß√£o com **DeepFace** para an√°lise facial profunda, identificando emo√ß√µes como alegria, tristeza, raiva, surpresa, etc.
* **Detec√ß√£o de Pessoas Deitadas (Oriented Object Detection)**: Uso inovador do **YOLO11-obb** (Oriented Bounding Box) para distinguir com precis√£o entre pessoas em p√© e deitadas, crucial para detec√ß√£o de quedas ou acidentes.
* **Classifica√ß√£o de Cena (Context Awareness)**: O sistema utiliza **YOLO11-cls** para identificar o ambiente (ex: escrit√≥rio, sala de estar, parque), permitindo valida√ß√µes contextuais.
* **Detec√ß√£o de Objetos Contextual**: Identifica objetos na cena (**YOLO11**) e valida se s√£o esperados ou an√¥malos para aquele ambiente (ex: uma cama em um escrit√≥rio √© uma anomalia).
* **Detec√ß√£o de Anomalias**: Motor de regras que combina dados comportamentais e visuais para alertar sobre:
  * Movimentos bruscos.
  * Picos de emo√ß√£o negativa.
  * Inatividade prolongada.
  * Inconsist√™ncias de cena (objetos proibidos).
* **Interface Gr√°fica Profissional**: Desenvolvida em **PyQt6**, com player de v√≠deo, gr√°ficos em tempo real (PyQtCharts) e pain√©is de estat√≠sticas.
* **Relat√≥rios Autom√°ticos**: Gera√ß√£o de relat√≥rios em TXT com resumo das ocorr√™ncias.

## üèóÔ∏è Arquitetura e Fluxo de Processamento

A aplica√ß√£o segue uma arquitetura modular, onde uma Thread de Processamento (`ProcessorThreadQt`) orquestra a execu√ß√£o sequencial dos modelos de IA frame a frame, sem congelar a interface do usu√°rio.

### Pipeline de Processamento

1. **Aquisi√ß√£o de Frame**: O v√≠deo √© lido frame a frame (com suporte a *frame skip* para performance).
2. **Classifica√ß√£o de Cena (SceneClassifier)**: Identifica o contexto global (ex: "Office"). Executado periodicamente.
3. **Detec√ß√£o Orientada (OrientedDetector)**: Verifica objetos rotacionados, essencial para identificar pessoas deitadas com precis√£o.
4. **Detec√ß√£o de Atividades (ActivityDetector)**: Detecta pessoas e keypoints (poses). Integra dados do *OrientedDetector* para refinar a classifica√ß√£o de postura.
5. **Extra√ß√£o de Faces (FaceDetector)**: Utiliza a geometria dos keypoints para recortar regi√µes faciais de alta probabilidade (Top-Down approach).
6. **An√°lise de Emo√ß√µes (EmotionAnalyzer)**: Processa os recortes faciais com DeepFace para extrair estados emocionais.
7. **Detec√ß√£o de Objetos (ObjectDetector)**: Varre o cen√°rio em busca de objetos gerais.
8. **Detec√ß√£o de Anomalias (AnomalyDetector)**: Cruza todas as informa√ß√µes (Cena + Objetos + A√ß√µes + Emo√ß√µes) contra regras pr√©-definidas para gerar alertas.
9. **Visualiza√ß√£o e UI**: Desenha bounding boxes e textos no frame e emite sinais para atualizar os gr√°ficos da GUI.

### Estrutura do Projeto

```text
TC-4/
‚îú‚îÄ‚îÄ gui_app.py              # Ponto de entrada da aplica√ß√£o
‚îú‚îÄ‚îÄ requirements.txt        # Lista de depend√™ncias Python
‚îú‚îÄ‚îÄ input/                  # Diret√≥rio para v√≠deos de entrada
‚îú‚îÄ‚îÄ output/                 # Diret√≥rio para v√≠deos processados
‚îú‚îÄ‚îÄ reports/                # Relat√≥rios gerados
‚îú‚îÄ‚îÄ models/                 # Pesos dos modelos YOLO e DeepFace
‚îî‚îÄ‚îÄ src/
    ‚îú‚îÄ‚îÄ config.py           # Configura√ß√µes globais e regras de contexto
    ‚îú‚îÄ‚îÄ gui/                # Interface Gr√°fica (PyQt6)
    ‚îÇ   ‚îú‚îÄ‚îÄ main_window_qt.py
    ‚îÇ   ‚îî‚îÄ‚îÄ threads/processor_thread_qt.py # Orquestrador do pipeline
    ‚îú‚îÄ‚îÄ activity_detector.py # Wrapper YOLO11-pose
    ‚îú‚îÄ‚îÄ emotion_analyzer.py  # Wrapper DeepFace
    ‚îú‚îÄ‚îÄ face_detector.py     # L√≥gica de extra√ß√£o facial
    ‚îú‚îÄ‚îÄ scene_classifier.py  # Wrapper YOLO11-cls
    ‚îú‚îÄ‚îÄ oriented_detector.py # Wrapper YOLO11-obb
    ‚îú‚îÄ‚îÄ object_detector.py   # Wrapper YOLO11-detect
    ‚îú‚îÄ‚îÄ anomaly_detector.py  # Motor de regras de anomalia
    ‚îî‚îÄ‚îÄ visualizer.py        # Renderiza√ß√£o visual (OpenCV/PIL)
```

## üõ†Ô∏è Instala√ß√£o e Configura√ß√£o

### Pr√©-requisitos

* **Python 3.10** ou superior (3.12 recomendado).
* **GPU NVIDIA** (Opcional, mas altamente recomendado para performance em tempo real). Drivers CUDA instalados.

### Passo a Passo

1. **Clone o reposit√≥rio e navegue at√© a pasta:**

    ```bash
    git clone <url-do-repositorio>
    cd TC-4
    ```

2. **Crie e ative um ambiente virtual:**

    ```bash
    python3 -m venv .venv
    source .venv/bin/activate  # Linux/Mac
    # .venv\Scripts\activate   # Windows
    ```

3. **Instale as depend√™ncias:**

    ```bash
    pip install -r requirements.txt
    ```

    *Nota: A primeira execu√ß√£o baixar√° automaticamente os modelos YOLO (~100MB cada) e DeepFace.*

4. **Execute a aplica√ß√£o:**

    ```bash
    python gui_app.py
    ```

## üìñ Como Usar

1. A interface abrir√° automaticamente.
2. Clique no √≠cone de **"Abrir Arquivo"** (canto superior esquerdo) para selecionar um v√≠deo da pasta `input/`.
3. Ajuste as configura√ß√µes se necess√°rio (bot√£o "Configura√ß√µes"):
    * **Frame Skip**: Aumente para maior velocidade (ex: 2 ou 3).
    * **Device**: CPU ou CUDA (GPU).
4. Clique no bot√£o **Play** (‚ñ∂) para iniciar a an√°lise.
5. Acompanhe os resultados em tempo real:
    * **V√≠deo**: Visualiza√ß√£o com anota√ß√µes de bounding boxes e labels.
    * **Estat√≠sticas**: Contadores de faces, anomalias e atividades.
    * **Gr√°ficos**: Distribui√ß√£o de emo√ß√µes e atividades (abas na parte inferior).
6. Ao final, o v√≠deo processado ser√° salvo na pasta `output/` e um relat√≥rio de texto em `reports/`.

## ‚öôÔ∏è Configura√ß√£o T√©cnica (`src/config.py`)

O arquivo `src/config.py` centraliza constantes importantes, como:

* `SCENE_CONTEXT_RULES`: Dicion√°rio que define quais objetos s√£o esperados ou an√¥malos em cada tipo de cena (escrit√≥rio, casa, rua).
* `ANOMALY_THRESHOLDS`: Limiares de sensibilidade para detec√ß√£o de anomalias.
* `EMOTION_THRESHOLDS`: Sensibilidade para cada tipo de emo√ß√£o.

---
**Tech Challenge Fase 4 - P√≥s Tech Data Analytics**
