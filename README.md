# Tech Challenge - Fase 4: AnÃ¡lise de VÃ­deo com IA

## DescriÃ§Ã£o

AplicaÃ§Ã£o de anÃ¡lise de vÃ­deo que utiliza tÃ©cnicas de **reconhecimento facial**, **anÃ¡lise de expressÃµes emocionais**, **detecÃ§Ã£o de atividades** e **identificaÃ§Ã£o de anomalias comportamentais**.

O sistema oferece **duas interfaces**:

- **CLI**: Processamento via linha de comando com player OpenCV integrado
- **GUI**: Interface grÃ¡fica moderna com visualizaÃ§Ã£o em tempo real, grÃ¡ficos e controles interativos

## Funcionalidades

| Funcionalidade | DescriÃ§Ã£o |
|----------------|-----------|
| **Reconhecimento Facial** | Detecta e rastreia rostos no vÃ­deo, atribuindo IDs Ãºnicos |
| **AnÃ¡lise de EmoÃ§Ãµes** | Classifica expressÃµes faciais (feliz, triste, raiva, etc.) |
| **DetecÃ§Ã£o de Atividades** | Identifica aÃ§Ãµes (caminhando, sentado, gesticulando, etc.) |
| **DetecÃ§Ã£o de Anomalias** | Identifica comportamentos atÃ­picos (movimentos bruscos, mudanÃ§as emocionais sÃºbitas) |
| **GeraÃ§Ã£o de RelatÃ³rio** | Cria resumo automÃ¡tico com estatÃ­sticas e insights |
| **Interface GUI** | VisualizaÃ§Ã£o interativa com grÃ¡ficos, estatÃ­sticas e controles de reproduÃ§Ã£o |

## Arquitetura

```
TC-4/
â”œâ”€â”€ main.py                 # CLI - Linha de comando
â”œâ”€â”€ gui_app.py              # GUI - Interface grÃ¡fica
â”œâ”€â”€ requirements.txt        # DependÃªncias do projeto
â”œâ”€â”€ .env.example            # Exemplo de configuraÃ§Ã£o
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py         # Exporta mÃ³dulos principais
â”‚   â”œâ”€â”€ config.py           # ConfiguraÃ§Ãµes centralizadas
â”‚   â”œâ”€â”€ face_detector.py    # Detector de rostos
â”‚   â”œâ”€â”€ emotion_analyzer.py # Analisador de emoÃ§Ãµes
â”‚   â”œâ”€â”€ activity_detector.py# Detector de atividades (YOLO11-pose)
â”‚   â”œâ”€â”€ anomaly_detector.py # Detector de anomalias
â”‚   â”œâ”€â”€ visualizer.py       # Desenho de anotaÃ§Ãµes nos frames
â”‚   â”œâ”€â”€ report_generator.py # Gerador de relatÃ³rios
â”‚   â””â”€â”€ gui/                # Interface grÃ¡fica
â”‚       â”œâ”€â”€ main_window.py  # Janela principal
â”‚       â”œâ”€â”€ widgets/        # Componentes da UI
â”‚       â”‚   â”œâ”€â”€ video_player.py
â”‚       â”‚   â”œâ”€â”€ stats_panel.py
â”‚       â”‚   â””â”€â”€ charts_panel.py
â”‚       â””â”€â”€ threads/        # Processamento em background
â”‚           â””â”€â”€ processor_thread.py
â”œâ”€â”€ input/                  # VÃ­deos de entrada
â”œâ”€â”€ output/                 # VÃ­deos processados
â”œâ”€â”€ reports/                # RelatÃ³rios gerados
â””â”€â”€ models/                 # Modelos YOLO baixados
```

## InstalaÃ§Ã£o

### 1. Clonar o repositÃ³rio

```bash
git clone <repo-url>
cd TC-4
```

### 2. Criar ambiente virtual (Python 3.12+)

```bash
python3.12 -m venv .venv
source .venv/bin/activate  # Linux/Mac
# ou
.venv\Scripts\activate     # Windows
```

### 3. Instalar dependÃªncias

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

### 4. Colocar o vÃ­deo na pasta `input/`

```bash
cp seu_video.mp4 input/
```

## Uso

### OpÃ§Ã£o 1: Interface GrÃ¡fica (Recomendado)

```bash
# Ativar ambiente virtual
source .venv/bin/activate

# Iniciar GUI
python gui_app.py
```

**Funcionalidades da GUI:**

- **Player de VÃ­deo**: Controles completos (play, pause, seek, tempo real)
- **Painel de EstatÃ­sticas**: Contadores ao vivo de faces, emoÃ§Ãµes, atividades e anomalias
- **GrÃ¡ficos Interativos**:
  - DistribuiÃ§Ã£o de emoÃ§Ãµes (barras)
  - DistribuiÃ§Ã£o de atividades (barras)
  - Timeline de eventos
  - AnÃ¡lise de anomalias (pizza)
- **Controles**: Processar, pausar, parar, salvar vÃ­deo
- **Barra de Status**: Progresso em tempo real, FPS, tempo estimado
- **Menu**: Abrir vÃ­deos, exportar relatÃ³rios, ajustes

**Requisitos de Sistema:**

- Python 3.12+ com Tkinter instalado (`python3.12-tkinter` no Linux)
- Ambiente grÃ¡fico (X11/Wayland no Linux, GUI nativa no Windows/Mac)

### OpÃ§Ã£o 2: Linha de Comando (CLI)

```bash
# Ativar ambiente virtual
source .venv/bin/activate

# Processar vÃ­deo padrÃ£o (definido em .env ou config.py)
python main.py

# Processar vÃ­deo especÃ­fico
python main.py input/seu_video.mp4

# Processar e reproduzir automaticamente (abre player OpenCV)
python main.py input/video.mp4 --show

# Ajustar intervalo de frames (mais rÃ¡pido, menos preciso)
python main.py input/video.mp4 --skip 3

# Definir arquivo de saÃ­da customizado
python main.py input/video.mp4 --output meu_resultado.mp4

# Ver todas as opÃ§Ãµes disponÃ­veis
python main.py --help
```

### Controles do Player (CLI --show e GUI)

| Tecla | AÃ§Ã£o |
| --- | --- |
| **Q** ou **ESC** | Sair do player |
| **EspaÃ§o** | Pausar/Continuar |
| **â† / A** | Voltar 10 segundos |
| **â†’ / D** | AvanÃ§ar 10 segundos |

### SaÃ­da no Console (CLI)

O sistema exibe em tempo real:

- Carregamento dos modelos de IA
- InformaÃ§Ãµes do vÃ­deo de entrada
- Barra de progresso detalhada (%, FPS, ETA)
- EstatÃ­sticas completas da anÃ¡lise:
  - Total de faces detectadas
  - Top 5 emoÃ§Ãµes com grÃ¡fico ASCII
  - Top 5 atividades com grÃ¡fico ASCII
  - Anomalias detectadas
- InformaÃ§Ãµes do arquivo gerado

## Tecnologias Utilizadas

| Categoria | Tecnologia |
| --- | --- |
| **Interface** | CustomTkinter (GUI), Tkinter (GUI base) |
| **VisÃ£o Computacional** | OpenCV, MediaPipe |
| **Reconhecimento Facial** | OpenCV Haar Cascades |
| **AnÃ¡lise de EmoÃ§Ãµes** | FER (Facial Expression Recognition) |
| **DetecÃ§Ã£o de Atividades** | YOLO11-pose (Ultralytics) |
| **Deep Learning** | PyTorch |
| **VisualizaÃ§Ã£o** | Matplotlib (grÃ¡ficos integrados) |
| **Threading** | Python threading (processamento assÃ­ncrono) |

## VÃ­deo Processado

O vÃ­deo de saÃ­da contÃ©m:

- âœ… Bounding boxes verdes para rostos detectados
- ğŸ˜Š Labels de emoÃ§Ãµes com confianÃ§a (ciano)
- ğŸƒ DetecÃ§Ã£o de atividades das pessoas (laranja)
- âš ï¸ Alertas visuais para anomalias (vermelho)

## Estrutura dos MÃ³dulos

### FaceDetector (`src/face_detector.py`)

- MÃ©todo padrÃ£o: Haar Cascades
- Rastreamento de IDs entre frames
- Suporte para MediaPipe e DNN

### EmotionAnalyzer (`src/emotion_analyzer.py`)

- Baseado em FER (Facial Expression Recognition)
- SuavizaÃ§Ã£o temporal para reduzir ruÃ­do
- 7 emoÃ§Ãµes: feliz, triste, raiva, medo, surpresa, nojo, neutro

### ActivityDetector (`src/activity_detector.py`)

- Usa YOLO11-pose para detecÃ§Ã£o de pessoas
- AnÃ¡lise de keypoints (17 pontos COCO)
- Detecta 9 atividades: em pÃ©, sentado, caminhando, correndo, acenando, apontando, danÃ§ando, agachado, braÃ§os levantados

### AnomalyDetector (`src/anomaly_detector.py`)

- AnÃ¡lise estatÃ­stica de comportamento
- DetecÃ§Ã£o de: movimentos bruscos, mudanÃ§as emocionais sÃºbitas, atividades incomuns
- HistÃ³rico temporal para baseline adaptativo

## Notas Importantes

- âœ… Projeto convertido de notebooks para aplicaÃ§Ã£o CLI simples
- ğŸš€ Performance otimizada com `frame_skip` configurÃ¡vel
- ğŸ“¹ Suporta qualquer formato de vÃ­deo compatÃ­vel com OpenCV
- ğŸ¯ YOLO11-pose oferece melhor precisÃ£o que YOLOv8

## Autor

Desenvolvido para o Tech Challenge - Fase 4 do curso de PÃ³s-GraduaÃ§Ã£o.

## LicenÃ§a

Este projeto Ã© de uso educacional.
